{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to python by creating a simple tracking example\n",
    "\n",
    "Python is a scripts based, obect oriented programing language. This means that objects can be create by stating MyNewObject = AnyValueYouMayWantToStore and that the code is written in a file/script that can be executed. Commonly such python scripts can be recognized by the .py file extension.  \n",
    "\n",
    "- Here we will use python in combination with a increasingly popular and very extensive open-source computer vision library OpenCV.\n",
    "\n",
    "- We will create a video reader that iterates over all frames of a video as input file. \n",
    "- Having access to each frame allows us to apply common image manipulations, such as background subtraction, thresholding, blurring and motion detection. \n",
    "- By using these image alterations moving objects can be clearly detected and, once detected, their positions can be stored as cartesian trajectories. This commonly refers to the term tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import python some usefull libraries\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define input video file\n",
    "video_file = '/home/fritz/Dropbox/Work/scioi/Experimente/2019_Fritz_Learning/2020_Fritz_Learning_Data04/04_10_videos/P.formosa/04_10_04/7_2020-07-24_143316_09-08.avi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a video player\n",
    "\n",
    "Create video player by iterating over all images/frames of the input video_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a named window, in which to visualize video frames\n",
    "cv2.namedWindow('Video Player')\n",
    "\n",
    "## enable video capture using input file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ## start grabbing/reading a frame from the capture\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    ## if the frame was sucessfully retreived ret == True, continue doing stuff...\n",
    "    if ret == True:\n",
    "        \n",
    "        ##########################################\n",
    "        ##                                      ##\n",
    "        ## -- INSERT IMAGE MANIPULATION HERE -- ##\n",
    "        ##                                      ##\n",
    "        ##########################################\n",
    "        \n",
    "        ## show retreived frame in the designated window that was created before using cv2.namedWindow()\n",
    "        cv2.imshow('Video Player',frame)\n",
    "       \n",
    "        ## in order for cv2.imshow() to work it must be followed by a cv2.waitkey(),\n",
    "        ## otherwise the retreiving proceess is too fast for the cv2.imshow() function to work\n",
    "        ## quit player using 'q' button\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "## destroy/close all created windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## release capture\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply image manipulations\n",
    "\n",
    "Here we apply simple image manipulations such as background subtraction and thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Subtraction\n",
    "\n",
    "Background Subtraction commonly refers to the process of creating a background image through accumulation of multiple images and subtracting this average image from each individual frame.\n",
    "\n",
    "The most important arguments in the function <code>cv2.createBackgroundSubtractorKNN()</code> are:\n",
    "\n",
    "<code>history</code> : refers to the number of images that are accumulated for the background <br>\n",
    "<code>detectShadows</code> : is a boolean (True/False) argument which turns the shadow detection on or off <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a named window, in which to visualize video frames\n",
    "cv2.namedWindow('Video Player')\n",
    "\n",
    "## creating a common background subtractor implemented in OpenCV\n",
    "backgroundsubtractor = cv2.createBackgroundSubtractorKNN(history=90, detectShadows=False)\n",
    "\n",
    "## enable video capture using input file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ## start grabbing/reading a frame from the capture\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    ## if the frame was sucessfully retreived ret == True, continue doing stuff...\n",
    "    if ret == True:\n",
    "        \n",
    "        ## subtract background from current frame\n",
    "        frame = backgroundsubtractor.apply(frame)     \n",
    "        \n",
    "        ## show retreived frame in the designated window that was created before using cv2.namedWindow()\n",
    "        cv2.imshow('Video Player',frame)\n",
    "       \n",
    "        ## in order for cv2.imshow() to work it must be followed by a cv2.waitkey(),\n",
    "        ## otherwise the retreiving proceess is too fast for the cv2.imshow() function to work\n",
    "        ## quit player using 'q' button\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "## destroy/close all created windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## release capture\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian blur\n",
    "\n",
    "In order to reduce noise/speckles in the image after subtracting the background we can utilize a process called smoothing or blurring. Gaussian bluring is a specific form of such, but basically the process is the same as in any other image smoothing process. \n",
    "\n",
    "Here the most important argument of the function <code>cv2.GaussianBlur()</code> is:\n",
    "\n",
    "<code>kernel</code> : The kernel is a square matrix (5x5 in this case) with uneven edge length. It is shifted over the image to create the smoothing/blurred effect. This has the advantage that small points/speckles become less visible and loose contrast.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a named window, in which to visualize video frames\n",
    "cv2.namedWindow('Video Player')\n",
    "\n",
    "## creating a common background subtractor implemented in OpenCV\n",
    "backgroundsubtractor = cv2.createBackgroundSubtractorKNN(history=90, detectShadows=False)\n",
    "\n",
    "## enable video capture using input file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ## start grabbing/reading a frame from the capture\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    ## if the frame was sucessfully retreived ret == True, continue doing stuff...\n",
    "    if ret == True:\n",
    "        \n",
    "        ## subtract background from current frame\n",
    "        frame = backgroundsubtractor.apply(frame)\n",
    "        \n",
    "        ## apply gaussian blur to image\n",
    "        kernel = (5,5)\n",
    "        frame = cv2.GaussianBlur(frame, kernel, 0)\n",
    "        \n",
    "        ## show retreived frame in the designated window that was created before using cv2.namedWindow()\n",
    "        cv2.imshow('Video Player',frame)\n",
    "       \n",
    "        ## in order for cv2.imshow() to work it must be followed by a cv2.waitkey(),\n",
    "        ## otherwise the retreiving proceess is too fast for the cv2.imshow() function to work\n",
    "        ## quit player using 'q' button\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "## destroy/close all created windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## release capture\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding\n",
    "\n",
    "Once we have applied the backgrond subtraction and blured the output image we can threshold the image again to retrieve only the moving objects we are interested in. Thresholding basically cuts out all pixels bellow a given threshold and results in a cleaner image. There are multiple approaches to thresholding of which only binary and adaptive will be highlighted here. \n",
    "\n",
    "1) Binary Thresholding: Image is thresholded to be within a given range, resulting in a black and white image <br>\n",
    "2) Adaptive Thresholding: Threshold is applied adaptively, meaning that changes in luminance, contrast and brightness can be accounted for. However the result is not as well standardized, as when using a binary filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a named window, in which to visualize video frames\n",
    "cv2.namedWindow('Video Player')\n",
    "\n",
    "## creating a common background subtractor implemented in OpenCV\n",
    "backgroundsubtractor = cv2.createBackgroundSubtractorKNN(history=90, detectShadows=False)\n",
    "\n",
    "## enable video capture using input file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ## start grabbing/reading a frame from the capture\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    ## if the frame was sucessfully retreived ret == True, continue doing stuff...\n",
    "    if ret == True:\n",
    "        \n",
    "        ## subtract background from current frame\n",
    "        frame = backgroundsubtractor.apply(frame)\n",
    "        \n",
    "        ## apply gaussian blur to image\n",
    "        kernel = (5,5)\n",
    "        frame = cv2.GaussianBlur(frame, kernel, 0)\n",
    "        \n",
    "        ## threshold image to be within given range (0-255) using a binary filter\n",
    "        min_thresh = 30\n",
    "        max_thresh = 255\n",
    "        ret_thresh, frame = cv2.threshold(frame, min_thresh, max_thresh, cv2.THRESH_BINARY)\n",
    "        \n",
    "        ## show retreived frame in the designated window that was created before using cv2.namedWindow()\n",
    "        cv2.imshow('Video Player',frame)\n",
    "       \n",
    "        ## in order for cv2.imshow() to work it must be followed by a cv2.waitkey(),\n",
    "        ## otherwise the retreiving proceess is too fast for the cv2.imshow() function to work\n",
    "        ## quit player using 'q' button\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "## destroy/close all created windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## release capture\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object detection\n",
    "\n",
    "For detecting objects of interest we can use the simplest approach, which is based on contour detection. It finds so called blobs within an image and allows these to be filtered by various aspects such as contour area or circularity.\n",
    "\n",
    "The provided function <code>cv2.findContours()</code> takes a thresholded and binarized image as input. The other key arguments can be tweaked to fit some more specific needs, but otherwise don't need to be of interest.  \n",
    "\n",
    "<code>cv2.drawContours()</code> visualized the detected <code>contours</code> and draws these onto the input image (in this case <code>frame</code> with color <code>bgr_color</code> and <code>linewidth</code>. The <code>index</code> refers to the index of the contour that should be drawn. -1 in this case means that all objects within <code>contours</code> should be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a named window, in which to visualize video frames\n",
    "cv2.namedWindow('Video Player')\n",
    "\n",
    "## creating a common background subtractor implemented in OpenCV\n",
    "backgroundsubtractor = cv2.createBackgroundSubtractorKNN(history=90, detectShadows=False)\n",
    "\n",
    "## enable video capture using input file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ## start grabbing/reading a frame from the capture\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    ## if the frame was sucessfully retreived ret == True, continue doing stuff...\n",
    "    if ret == True:\n",
    "        \n",
    "        ## subtract background from current frame\n",
    "        frame = backgroundsubtractor.apply(frame)\n",
    "        \n",
    "        ## apply gaussian blur to image\n",
    "        kernel = (5,5)\n",
    "        frame = cv2.GaussianBlur(frame, kernel, 0)\n",
    "        \n",
    "        ## threshold image to be within given range (0-255) using a binary filter\n",
    "        min_thresh = 30\n",
    "        max_thresh = 255\n",
    "        ret_thresh, frame = cv2.threshold(frame, min_thresh, max_thresh, cv2.THRESH_BINARY)\n",
    "        \n",
    "        ## detect contours\n",
    "        contours, hierarchy = cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        ## in order to draw contours onto the image in color we have to first convert the grayscale image to color:\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        ## we can now draw the detected contours onto the image\n",
    "        linewidth = 2\n",
    "        bgr_color = (255,0,0)\n",
    "        index = -1\n",
    "        frame = cv2.drawContours(frame, contours, index, color, linewidth)\n",
    "        \n",
    "        ## show retreived frame in the designated window that was created before using cv2.namedWindow()\n",
    "        cv2.imshow('Video Player',frame)\n",
    "       \n",
    "        ## in order for cv2.imshow() to work it must be followed by a cv2.waitkey(),\n",
    "        ## otherwise the retreiving proceess is too fast for the cv2.imshow() function to work\n",
    "        ## quit player using 'q' button\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "## destroy/close all created windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## release capture\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering detections\n",
    "\n",
    "We can further filter the detected objects. For simplicity we will use size here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a named window, in which to visualize video frames\n",
    "cv2.namedWindow('Video Player')\n",
    "\n",
    "## creating a common background subtractor implemented in OpenCV\n",
    "backgroundsubtractor = cv2.createBackgroundSubtractorKNN(history=90, detectShadows=False)\n",
    "\n",
    "## enable video capture using input file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ## start grabbing/reading a frame from the capture\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    ## if the frame was sucessfully retreived ret == True, continue doing stuff...\n",
    "    if ret == True:\n",
    "        \n",
    "        ## subtract background from current frame\n",
    "        frame = backgroundsubtractor.apply(frame)\n",
    "        \n",
    "        ## apply gaussian blur to image\n",
    "        kernel = (5,5)\n",
    "        frame = cv2.GaussianBlur(frame, kernel, 0)\n",
    "        \n",
    "        ## threshold image to be within given range (0-255) using a binary filter\n",
    "        min_thresh = 30\n",
    "        max_thresh = 255\n",
    "        ret_thresh, frame = cv2.threshold(frame, min_thresh, max_thresh, cv2.THRESH_BINARY)\n",
    "        \n",
    "        ## detect contours\n",
    "        contours, hierarchy = cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        ## in order to draw contours onto the image in color we have to first convert the grayscale image to color:\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        ## set limits for accetable contour area in pixel\n",
    "        contour_min_area = 10\n",
    "        contour_max_area = 100\n",
    "        \n",
    "        ## create list to store valid contour indexes\n",
    "        c_index = []\n",
    "        \n",
    "        ## loop over, and index all detected contours in the current frame\n",
    "        for i, contour in enumerate(contours):\n",
    "            \n",
    "            ## loop over, and index all detected contours in the current frame\n",
    "            c_area = cv2.contourArea(contour)\n",
    "            \n",
    "            ## check if contour area is within range\n",
    "            if contour_min_area <= c_area <= contour_max_area:\n",
    "                \n",
    "                ## if contour area is within range, store its index in the index list\n",
    "                c_index.append(i)\n",
    "        \n",
    "        ## if any contour fit the criterium, use only the contours that were indexed\n",
    "        if len(c_index) > 0:\n",
    "            contours = np.array([contours[i] for i in c_index])\n",
    "            \n",
    "        ## else continue with an empty list of detections\n",
    "        else:\n",
    "            contours = []\n",
    "    \n",
    "        ## we can now draw the detected contours onto the image\n",
    "        linewidth = cv2.FILLED ## filled contours\n",
    "        bgr_color = (255,0,0)\n",
    "        index = -1\n",
    "        frame = cv2.drawContours(frame, contours, index, bgr_color, linewidth)\n",
    "        \n",
    "        ## show retreived frame in the designated window that was created before using cv2.namedWindow()\n",
    "        cv2.imshow('Video Player',frame)\n",
    "       \n",
    "        ## in order for cv2.imshow() to work it must be followed by a cv2.waitkey(),\n",
    "        ## otherwise the retreiving proceess is too fast for the cv2.imshow() function to work\n",
    "        ## quit player using 'q' button\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "            \n",
    "## destroy/close all created windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## release capture\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking\n",
    "\n",
    "In this case we are not properly tracking, since each individual detection is equipped with a specific identity which is kept over time. This can only be done if considering the spatial separation between object or calculating some kind of similarity metric between all detections.\n",
    "\n",
    "The coordinates for a detection are calculated as the mean of all x or y coordinates for each pixel within this contour. Detected contours have the structure contour = ([number of pixels],[index],[x,y]). : indicates that all indexes of a list/array should be used. Therefore, we calculate x for example by using all pixels and each index (although the index here is always 1) contour[:,:,0]. 0 here refers to the x coordinate and 1 would apply to the y coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fritz/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "## create a named window, in which to visualize video frames\n",
    "cv2.namedWindow('Video Player')\n",
    "\n",
    "## creating a common background subtractor implemented in OpenCV\n",
    "backgroundsubtractor = cv2.createBackgroundSubtractorKNN(history=90, detectShadows=False)\n",
    "\n",
    "## enable video capture using input file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ## start grabbing/reading a frame from the capture\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    ## if the frame was sucessfully retreived ret == True, continue doing stuff...\n",
    "    if ret == True:\n",
    "        \n",
    "        ## subtract background from current frame\n",
    "        frame = backgroundsubtractor.apply(frame)\n",
    "        \n",
    "        ## apply gaussian blur to image\n",
    "        kernel = (5,5)\n",
    "        frame = cv2.GaussianBlur(frame, kernel, 0)\n",
    "        \n",
    "        ## threshold image to be within given range (0-255) using a binary filter\n",
    "        min_thresh = 30\n",
    "        max_thresh = 255\n",
    "        ret_thresh, frame = cv2.threshold(frame, min_thresh, max_thresh, cv2.THRESH_BINARY)\n",
    "        \n",
    "        ## detect contours\n",
    "        contours, hierarchy = cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        ## in order to draw contours onto the image in color we have to first convert the grayscale image to color:\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        ## set limits for accetable contour area in pixel\n",
    "        contour_min_area = 10\n",
    "        contour_max_area = 100\n",
    "        \n",
    "        ## create list to store valid contour indexes\n",
    "        c_index = []\n",
    "        \n",
    "        ## loop over, and index all detected contours in the current frame\n",
    "        for i, contour in enumerate(contours):\n",
    "            \n",
    "            ## loop over, and index all detected contours in the current frame\n",
    "            c_area = cv2.contourArea(contour)\n",
    "            \n",
    "            ## check if contour area is within range\n",
    "            if contour_min_area <= c_area <= contour_max_area:\n",
    "                \n",
    "                ## if contour area is within range, store its index in the index list\n",
    "                c_index.append(i)\n",
    "        \n",
    "        ## if any contour fit the criterium, use only the contours that were indexed\n",
    "        if len(c_index) > 0:\n",
    "            contours = np.array([contours[i] for i in c_index])\n",
    "    \n",
    "            \n",
    "        ## else continue with an empty list of detections\n",
    "        else:\n",
    "            contours = []\n",
    "    \n",
    "        ## calculate centroid for each contour:\n",
    "        for contour in contours:\n",
    "            \n",
    "            ## calculate cartesian coordinates as mean of all points making up a contour\n",
    "            x = np.mean(contour[:,:,0])\n",
    "            y = np.mean(contour[:,:,1])\n",
    "            \n",
    "            ## round the resulting results to 2 decimals\n",
    "            x = np.round(x,2)\n",
    "            y = np.round(y,2)\n",
    "            \n",
    "            ## we can draw the xy-coordinates or a radius around the centroid\n",
    "            radius = 9\n",
    "            color = (0,200,255)\n",
    "            thickness = 1\n",
    "            frame = cv2.circle(frame, (int(x),int(y)), radius, color, thickness)\n",
    "            \n",
    "        ## we can now draw the detected contours onto the image\n",
    "        linewidth = cv2.FILLED ## filled contours\n",
    "        bgr_color = (255,0,0)\n",
    "        index = -1\n",
    "        frame = cv2.drawContours(frame, contours, index, bgr_color, linewidth)\n",
    "        \n",
    "        ## show retreived frame in the designated window that was created before using cv2.namedWindow()\n",
    "        cv2.imshow('Video Player',frame)\n",
    "       \n",
    "        ## in order for cv2.imshow() to work it must be followed by a cv2.waitkey(),\n",
    "        ## otherwise the retreiving proceess is too fast for the cv2.imshow() function to work\n",
    "        ## quit player using 'q' button\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "            \n",
    "## destroy/close all created windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## release capture\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
